"""
Pipeline to estimate fine-scale recombination maps from polymorphism data
Preprocesing data - Making a consistent population dataset
"""

"""
Configuration of the analysis
i.e. dataset, name of chromosome, population to sample
"""
configfile: "config.yaml"


"""In addition to the configfile statement, config values can be overwritten via the command line"""
dataset=config["dataset"] # Name of your dataset directory and prefix of your vcf file
maxk=config["maxk"]

wdir={config["workingdir"]} + dataset

wildcard_constraints:
    wdir=wdir,
    dataset=dataset

rule all:
    """
    One ring to rule them all"
    """
    input:
        expand("{wdir}/structure/popstatistics.csv", wdir=wdir)
    shell:
        "echo 'Preprocessing: Finished to infer population structure'"


# The global dataset is trimmed for SNPs
# and individuals if a 'samplelist' file is provided
# Otherwise all individuals are kept
rule trimming_vcf:
    """
    A first step to trim every 'sample' dataset to the same quality criteria
    """
    input:
        "{wdir}/{dataset}.vcf.gz"
    output:
    	"{wdir}/{dataset}.trimmed.vcf.gz"
    log:
        "{wdir}/logs/{dataset}.trimming_vcf.log"
    conda:
        "envs/vcftools.yaml"
    shell:
        """
        if [ -f "{wdir}/samplelist" ];
        then
            vcftools --gzvcf {input} --out {wdir}/out --recode --keep {wdir}/samplelist --maf config[maf] --max-missing config[maxmissing]
            mv {wdir}/out.recode.vcf {wdir}/{dataset}.trimmed.vcf
            bgzip -f {wdir}/{dataset}.trimmed.vcf
            rm {wdir}/out.log
        else
            vcftools --gzvcf {input} --out {wdir}/out --recode --maf config[maf] --max-missing config[maxmissing]
            mv {wdir}/out.recode.vcf {wdir}/{dataset}.trimmed.vcf
            bgzip {wdir}/{dataset}.trimmed.vcf
            rm {wdir}/out.log
        fi
        # Collapse duplicate SNPs with identical positions
        bcftools norm -d all {wdir}/{dataset}.trimmed.vcf.gz -o {wdir}/{dataset}.trimmed.vcf
        rm {wdir}/{dataset}.trimmed.vcf.gz
        bgzip {wdir}/{dataset}.trimmed.vcf
        """


# Use vcftools to export to .ped format with the --plink switch.  Then convert the .ped to .bed using Plink.  Faststructure will read the .bed format files (there are three files for each project)
rule vcf2structure:
    """
    Convert the vcf file to bed format for FastStructure
    """
    input:
        "{wdir}/{dataset}.trimmed.vcf.gz"
    output:
        bed = "{wdir}/{dataset}.bed",
        bam = "{wdir}/{dataset}.fam",
        bim = "{wdir}/{dataset}.bim"
    log:
        "{wdir}/logs/{dataset}.vcf2structure.log"
    conda:
        "envs/vcftools.yaml"
    shell:
        """
        plink --vcf {input} --out {wdir}/{dataset}
        """


rule faststructure:
    """
    FastStructure
    Detects population structure and infer genetic clusters
    Produces diagnostic plots and summary statistics
    to help selecting the best population for recombination map
    """
    input:
        bed = expand("{wdir}/{dataset}.bed", wdir=wdir, dataset=dataset),
        k = expand("{k}", k=range(1,maxk+1))
    output:
        expand("{wdir}/structure/faststructure.{k}.log", wdir=wdir, k=range(1,maxk+1)),
        expand("{wdir}/structure/faststructure.{k}.meanP", wdir=wdir, k=range(1,maxk+1)),
        expand("{wdir}/structure/faststructure.{k}.varP", wdir=wdir, k=range(1,maxk+1)),
        expand("{wdir}/structure/faststructure.{k}.meanQ", wdir=wdir, k=range(1,maxk+1)),
        expand("{wdir}/structure/faststructure.{k}.varQ", wdir=wdir, k=range(1,maxk+1))
    log:
        expand("{wdir}/logs/faststructure.{k}.log", wdir=wdir, k=range(1,maxk+1))
    shell:
        """
<<<<<<< HEAD
        #for k in {{1..{maxk}}}
        #do
        singularity exec --bind {wdir}:/faststructure/data faststructure.simg python /faststructure/structure.py -K {k} --input=/faststructure/data/{dataset} --output=/faststructure/data/structure/faststructure --full --seed=100
        #done
=======
        for k in $(seq 1 {maxk})
        do
            singularity exec --bind $PWD:/mnt faststructure.simg python /faststructure/structure.py -K $k --input=/mnt/{wdir}/{dataset} --output=/mnt/{wdir}/structure/faststructure --full --seed=42
        done
>>>>>>> 9038ac8bc8f4066987bb370ca72d75c572f11946
        """


rule distruct:
    """
    Distruct Plots
    """
    input:
        expand("{wdir}/structure/faststructure.{k}.log", wdir=wdir, k=range(1,maxk+1)),
        expand("{wdir}/structure/faststructure.{k}.meanP", wdir=wdir, k=range(1,maxk+1)),
        expand("{wdir}/structure/faststructure.{k}.varP", wdir=wdir, k=range(1,maxk+1)),
        expand("{wdir}/structure/faststructure.{k}.meanQ", wdir=wdir, k=range(1,maxk+1)),
        expand("{wdir}/structure/faststructure.{k}.varQ", wdir=wdir, k=range(1,maxk+1))
    output:
        expand("{wdir}/structure/distruct.{k}.svg", wdir=wdir, k=range(1,maxk+1))
    log:
        expand("{wdir}/logs/distruct.{k}.log", wdir=wdir, k=range(1,maxk+1))
    shell:
        """
        for k in {{1..{maxk}}}
        do
            singularity exec --bind {wdir}:/faststructure/data faststructure.simg python /faststructure/distruct.py -K $k --input=/faststructure/data/structure/faststructure --output=/faststructure/data/structure/distruct.$k.svg
        done
        """


rule choose_k:
    """
    Choose the best K value
    """
    input:
        expand("{wdir}/structure/distruct.{k}.svg", wdir=wdir, k=range(1,maxk+1))
    output:
        "{wdir}/structure/chooseK"
    log:
        "{wdir}/logs/chooseK"
    shell:
        """
        echo $(singularity exec --bind {wdir}:/faststructure/data faststructure.simg python /faststructure/chooseK.py --input=/faststructure/data/structure/faststructure) > {wdir}/structure/chooseK
        """


rule indlist:
    """
    The list of individuals
    """
    input:
        "{wdir}/structure/chooseK"
    output:
        "{wdir}/indlist"
    log:
        "{wdir}/logs/indlist.log"
    shell:
        """
        bcftools query -l {wdir}/{dataset}.trimmed.vcf.gz > {wdir}/indlist
        """


rule k_statistics:
    """
    Report summary statistics for each population in each K chosen
    to help identify the best config K/population
    Pop. statistic csv file contains columns K, pop number and then columns of statistics
    Headers, statistics are:
    - number of individuals
    - missing data per locus (proportion)
    - missing data per individual (proportion)
    - He
    - Ho
    - Fis
    """
    input:
        "{wdir}/indlist"
    output:
        "{wdir}/structure/popstatistics.csv"
    log:
        "{wdir}/logs/k_statistics.log"
    conda:
        "envs/vcftools.yaml"
    shell:
        """
        echo K pop n missing_locus missing_ind pi He Ho Fis Admixture > {wdir}/structure/popstatistics.csv
        # For each K
        maxk={config[maxk]}
        for K in {1..$maxk}; do
        # Get the list of individuals of each population
        perl -ane '$r = 0; for my $i (1 .. $#F) {{$r = $i if $F[$i] > $F[$r];}} print $r + 1, " ";' < {wdir}/structure/faststructure.$K.meanQ > {wdir}/structure/clusters.tmp
        sed -i -e "s/\\s\\+/\\n/g" {wdir}/structure/clusters.tmp
        paste {wdir}/indlist {wdir}/structure/cluster.tmp > {wdir}/structure/cluster2.tmp
        paste {wdir}/structure/cluster2.tmp {wdir}/structure/faststructure.$K.meanQ > {wdir}/structure/cluster.$K.list
        rm *.tmp
        # For each population, compute statistics
        for pop in {1..$K}; do
        awk -F' ' '{{if($2==$pop) print $1}}' {wdir}/structure/cluster.$K.list > {wdir}/structure/poplist.$K.$pop
        # Compute popstatistics
        n=$(wc -l {wdir}/structure/poplist.$K.$pop)
        vcftools -gzvcf {wdir}/{dataset}.trimmed.vcf.gz --keep {wdir}/structure/poplist.$K.$pop --missing-indv --missing-site --site-pi --het
        # Add to the popstatistics csv files
        echo $K $pop $n >> {wdir}/structure/popstatistics.csv
        done
        done
        """

